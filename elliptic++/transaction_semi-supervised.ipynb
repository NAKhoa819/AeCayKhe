{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86cf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go \n",
    "import plotly.offline as py \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4543cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba92dab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transaction features: \n",
      "\n",
      "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
      "0            3321          1        -0.169615        -0.184668   \n",
      "1           11108          1        -0.137586        -0.184668   \n",
      "2           51816          1        -0.170103        -0.184668   \n",
      "3           68869          1        -0.114267        -0.184668   \n",
      "4           89273          1         5.202107        -0.210553   \n",
      "...           ...        ...              ...              ...   \n",
      "203764  158304003         49        -0.165622        -0.139563   \n",
      "203765  158303998         49        -0.167040        -0.139563   \n",
      "203766  158303966         49        -0.167040        -0.139563   \n",
      "203767  161526077         49        -0.172212        -0.139573   \n",
      "203768  194103537         49        -0.172212        -0.139573   \n",
      "\n",
      "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
      "0             -1.201369        -0.121970        -0.043875        -0.113002   \n",
      "1             -1.201369        -0.121970        -0.043875        -0.113002   \n",
      "2             -1.201369        -0.121970        -0.043875        -0.113002   \n",
      "3             -1.201369         0.028105        -0.043875        -0.113002   \n",
      "4             -1.756361        -0.121970       260.090707        -0.113002   \n",
      "...                 ...              ...              ...              ...   \n",
      "203764         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203765         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203766         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203767         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203768         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "\n",
      "        Local_feature_7  Local_feature_8  ...  in_BTC_min  in_BTC_max  \\\n",
      "0             -0.061584        -0.160199  ...    0.534072    0.534072   \n",
      "1             -0.061584        -0.127429  ...    5.611878    5.611878   \n",
      "2             -0.061584        -0.160699  ...    0.456608    0.456608   \n",
      "3              0.547008        -0.161652  ...    0.308900    8.000000   \n",
      "4             -0.061584         5.335864  ...  852.164680  852.164680   \n",
      "...                 ...              ...  ...         ...         ...   \n",
      "203764        -0.061584        -0.156113  ...         NaN         NaN   \n",
      "203765        -0.061584        -0.157564  ...         NaN         NaN   \n",
      "203766        -0.061584        -0.157564  ...         NaN         NaN   \n",
      "203767        -0.061584        -0.162856  ...         NaN         NaN   \n",
      "203768        -0.061584        -0.162856  ...         NaN         NaN   \n",
      "\n",
      "        in_BTC_mean  in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  \\\n",
      "0          0.534072       0.534072      0.534072  1.668990e-01     0.367074   \n",
      "1          5.611878       5.611878      5.611878  5.861940e-01     5.025584   \n",
      "2          0.456608       0.456608      0.456608  2.279902e-01     0.228518   \n",
      "3          3.102967       1.000000      9.308900  1.229000e+00     8.079800   \n",
      "4        852.164680     852.164680    852.164680  1.300000e-07    41.264036   \n",
      "...             ...            ...           ...           ...          ...   \n",
      "203764          NaN            NaN           NaN           NaN          NaN   \n",
      "203765          NaN            NaN           NaN           NaN          NaN   \n",
      "203766          NaN            NaN           NaN           NaN          NaN   \n",
      "203767          NaN            NaN           NaN           NaN          NaN   \n",
      "203768          NaN            NaN           NaN           NaN          NaN   \n",
      "\n",
      "        out_BTC_mean  out_BTC_median  out_BTC_total  \n",
      "0           0.266986        0.266986       0.533972  \n",
      "1           2.805889        2.805889       5.611778  \n",
      "2           0.228254        0.228254       0.456508  \n",
      "3           4.654400        4.654400       9.308800  \n",
      "4           0.065016        0.000441     852.164680  \n",
      "...              ...             ...            ...  \n",
      "203764           NaN             NaN            NaN  \n",
      "203765           NaN             NaN            NaN  \n",
      "203766           NaN             NaN            NaN  \n",
      "203767           NaN             NaN            NaN  \n",
      "203768           NaN             NaN            NaN  \n",
      "\n",
      "[203769 rows x 184 columns]\n",
      "\n",
      "Transaction classes: \n",
      "\n",
      "             txId  class\n",
      "0            3321      3\n",
      "1           11108      3\n",
      "2           51816      3\n",
      "3           68869      2\n",
      "4           89273      2\n",
      "...           ...    ...\n",
      "203764  158304003      3\n",
      "203765  158303998      3\n",
      "203766  158303966      3\n",
      "203767  161526077      3\n",
      "203768  194103537      3\n",
      "\n",
      "[203769 rows x 2 columns]\n",
      "\n",
      "Transaction-Transaction edgelist: \n",
      "\n",
      "            txId1      txId2\n",
      "0       230425980    5530458\n",
      "1       232022460  232438397\n",
      "2       230460314  230459870\n",
      "3       230333930  230595899\n",
      "4       232013274  232029206\n",
      "...           ...        ...\n",
      "234350  158365409  157930723\n",
      "234351  188708874  188708879\n",
      "234352  157659064  157659046\n",
      "234353   87414554  106877725\n",
      "234354  158589452  158589457\n",
      "\n",
      "[234355 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\uit\\\\elliptic\\\\Elliptic_Dataset\")\n",
    "print(\"\\nTransaction features: \\n\")\n",
    "df_txs_features = pd.read_csv(\"txs_features.csv\")\n",
    "print(df_txs_features)\n",
    "\n",
    "print(\"\\nTransaction classes: \\n\")\n",
    "df_txs_classes = pd.read_csv(\"txs_classes.csv\")\n",
    "print(df_txs_classes)\n",
    "\n",
    "print(\"\\nTransaction-Transaction edgelist: \\n\")\n",
    "df_txs_edgelist = pd.read_csv(\"txs_edgelist.csv\")\n",
    "\n",
    "print(df_txs_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f0eb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "txs_features.csv for txId = 272145560\n",
      "\n",
      "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
      "105573  272145560         24        -0.155493        -0.107012   \n",
      "\n",
      "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
      "105573        -1.201369         -0.12197        -0.043875        -0.113002   \n",
      "\n",
      "        Local_feature_7  Local_feature_8  ...  in_BTC_min  in_BTC_max  \\\n",
      "105573        -0.061584        -0.145749  ...      2.7732      2.7732   \n",
      "\n",
      "        in_BTC_mean  in_BTC_median  in_BTC_total  out_BTC_min  out_BTC_max  \\\n",
      "105573       2.7732         2.7732        2.7732     0.001917     2.770883   \n",
      "\n",
      "        out_BTC_mean  out_BTC_median  out_BTC_total  \n",
      "105573        1.3864          1.3864         2.7728  \n",
      "\n",
      "[1 rows x 184 columns]\n",
      "\n",
      "txs_classes.csv for txId = 272145560\n",
      "\n",
      "             txId  class\n",
      "105573  272145560      1\n",
      "\n",
      "txs_edgelist.csv for txId = 272145560\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId1</th>\n",
       "      <th>txId2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123072</th>\n",
       "      <td>272145560</td>\n",
       "      <td>296926618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123272</th>\n",
       "      <td>272145560</td>\n",
       "      <td>272145556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125873</th>\n",
       "      <td>299475624</td>\n",
       "      <td>272145560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            txId1      txId2\n",
       "123072  272145560  296926618\n",
       "123272  272145560  272145556\n",
       "125873  299475624  272145560"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\ntxs_features.csv for txId = 272145560\\n\")\n",
    "print(df_txs_features[df_txs_features['txId']==272145560])\n",
    "\n",
    "print(\"\\ntxs_classes.csv for txId = 272145560\\n\")\n",
    "print(df_txs_classes[df_txs_classes['txId']==272145560])\n",
    "\n",
    "print(\"\\ntxs_edgelist.csv for txId = 272145560\\n\")\n",
    "df_txs_edgelist[(df_txs_edgelist['txId1']==272145560) | (df_txs_edgelist['txId2']==272145560)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb260f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "3    157205\n",
      "2     42019\n",
      "1      4545\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_txs_features = df_txs_features.merge(df_txs_classes, left_on = \"txId\" , right_on = \"txId\" , how = \"left\")\n",
    "# print(txs.shape)\n",
    "\n",
    "print(df_txs_features[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b305d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>Time step</th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>1.668990e-01</td>\n",
       "      <td>0.367074</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.533972</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11108</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.127429</td>\n",
       "      <td>...</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.861940e-01</td>\n",
       "      <td>5.025584</td>\n",
       "      <td>2.805889</td>\n",
       "      <td>2.805889</td>\n",
       "      <td>5.611778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51816</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.170103</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>2.279902e-01</td>\n",
       "      <td>0.228518</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0.456508</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68869</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.114267</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>0.547008</td>\n",
       "      <td>-0.161652</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.102967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.308900</td>\n",
       "      <td>1.229000e+00</td>\n",
       "      <td>8.079800</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>9.308800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89273</td>\n",
       "      <td>1</td>\n",
       "      <td>5.202107</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>260.090707</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>5.335864</td>\n",
       "      <td>...</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>1.300000e-07</td>\n",
       "      <td>41.264036</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202799</th>\n",
       "      <td>194747812</td>\n",
       "      <td>49</td>\n",
       "      <td>0.558398</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>...</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>1.653300e+00</td>\n",
       "      <td>114.299544</td>\n",
       "      <td>57.976422</td>\n",
       "      <td>57.976422</td>\n",
       "      <td>115.952844</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202800</th>\n",
       "      <td>194747925</td>\n",
       "      <td>49</td>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>...</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>2.035300e-02</td>\n",
       "      <td>114.229700</td>\n",
       "      <td>57.125027</td>\n",
       "      <td>57.125027</td>\n",
       "      <td>114.250053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202801</th>\n",
       "      <td>194748063</td>\n",
       "      <td>49</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.569524</td>\n",
       "      <td>...</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>9.257490e-01</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>56.803363</td>\n",
       "      <td>56.803363</td>\n",
       "      <td>113.606726</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202802</th>\n",
       "      <td>194748070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.537760</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>...</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>3.026970e-01</td>\n",
       "      <td>112.378235</td>\n",
       "      <td>56.340466</td>\n",
       "      <td>56.340466</td>\n",
       "      <td>112.680932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202803</th>\n",
       "      <td>194835939</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.152788</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.161066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>3.995460e-01</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
       "0            3321          1        -0.169615        -0.184668   \n",
       "1           11108          1        -0.137586        -0.184668   \n",
       "2           51816          1        -0.170103        -0.184668   \n",
       "3           68869          1        -0.114267        -0.184668   \n",
       "4           89273          1         5.202107        -0.210553   \n",
       "...           ...        ...              ...              ...   \n",
       "202799  194747812         49         0.558398        -0.198956   \n",
       "202800  194747925         49         0.547658        -0.198956   \n",
       "202801  194748063         49         0.543600        -0.198853   \n",
       "202802  194748070         49         0.537760        -0.198853   \n",
       "202803  194835939         49        -0.170463        -0.152788   \n",
       "\n",
       "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
       "0             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "1             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "2             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "3             -1.201369         0.028105        -0.043875        -0.113002   \n",
       "4             -1.756361        -0.121970       260.090707        -0.113002   \n",
       "...                 ...              ...              ...              ...   \n",
       "202799        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202800        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202801        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202802        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202803         1.018602        -0.121970        -0.063725        -0.113002   \n",
       "\n",
       "        Local_feature_7  Local_feature_8  ...  in_BTC_max  in_BTC_mean  \\\n",
       "0             -0.061584        -0.160199  ...    0.534072     0.534072   \n",
       "1             -0.061584        -0.127429  ...    5.611878     5.611878   \n",
       "2             -0.061584        -0.160699  ...    0.456608     0.456608   \n",
       "3              0.547008        -0.161652  ...    8.000000     3.102967   \n",
       "4             -0.061584         5.335864  ...  852.164680   852.164680   \n",
       "...                 ...              ...  ...         ...          ...   \n",
       "202799        -0.061584         0.584665  ...  115.952889   115.952889   \n",
       "202800        -0.061584         0.573676  ...  114.250098   114.250098   \n",
       "202801        -0.061584         0.569524  ...  113.606771   113.606771   \n",
       "202802        -0.061584         0.563549  ...  112.680977   112.680977   \n",
       "202803        -0.061584        -0.161066  ...    0.399769     0.399769   \n",
       "\n",
       "        in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  out_BTC_mean  \\\n",
       "0            0.534072      0.534072  1.668990e-01     0.367074      0.266986   \n",
       "1            5.611878      5.611878  5.861940e-01     5.025584      2.805889   \n",
       "2            0.456608      0.456608  2.279902e-01     0.228518      0.228254   \n",
       "3            1.000000      9.308900  1.229000e+00     8.079800      4.654400   \n",
       "4          852.164680    852.164680  1.300000e-07    41.264036      0.065016   \n",
       "...               ...           ...           ...          ...           ...   \n",
       "202799     115.952889    115.952889  1.653300e+00   114.299544     57.976422   \n",
       "202800     114.250098    114.250098  2.035300e-02   114.229700     57.125027   \n",
       "202801     113.606771    113.606771  9.257490e-01   112.680977     56.803363   \n",
       "202802     112.680977    112.680977  3.026970e-01   112.378235     56.340466   \n",
       "202803       0.399769      0.399769  3.995460e-01     0.399546      0.399546   \n",
       "\n",
       "        out_BTC_median  out_BTC_total  class  \n",
       "0             0.266986       0.533972      3  \n",
       "1             2.805889       5.611778      3  \n",
       "2             0.228254       0.456508      3  \n",
       "3             4.654400       9.308800      2  \n",
       "4             0.000441     852.164680      2  \n",
       "...                ...            ...    ...  \n",
       "202799       57.976422     115.952844      3  \n",
       "202800       57.125027     114.250053      3  \n",
       "202801       56.803363     113.606726      3  \n",
       "202802       56.340466     112.680932      3  \n",
       "202803        0.399546       0.399546      3  \n",
       "\n",
       "[202804 rows x 185 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txs_features = df_txs_features.dropna()\n",
    "df_txs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e3f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_txs_features.columns[168:]:\n",
    "    if column != \"class\":\n",
    "        feature = np.array(df_txs_features[column]).reshape(-1,1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(feature)\n",
    "        feature_scaled = scaler.transform(feature)\n",
    "        df_txs_features[column] = feature_scaled.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6763c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "3    156759\n",
      "2     41500\n",
      "1      4545\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove 'unknown' transactions\n",
    "data = df_txs_features[\"txId\"] #.loc[(df_txs_features['class'] != 3), 'txId']\n",
    "df_txs_features_selected = df_txs_features.loc[df_txs_features['txId'].isin(data)]\n",
    "print(df_txs_features_selected[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d117c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: binary classification of 0,1\n",
    "# 0: licit, 1: illicit\n",
    "\n",
    "X_data = df_txs_features_selected.loc[(df_txs_features_selected['Time step'] < 35) & (df_txs_features_selected['class'] != 3), 'txId']\n",
    "X_training_timesteps = df_txs_features_selected.loc[df_txs_features_selected['txId'].isin(X_data)]\n",
    "X_train = X_training_timesteps.drop(columns=['txId', 'class', 'Time step'])\n",
    "\n",
    "X_data_test = df_txs_features_selected.loc[(df_txs_features_selected['Time step'] >= 35), 'txId']\n",
    "X_testing_timesteps = df_txs_features_selected.loc[df_txs_features_selected['txId'].isin(X_data_test)]\n",
    "X_test = X_testing_timesteps.drop(columns=['txId', 'class', 'Time step'])\n",
    "\n",
    "X_data_test_class01 = df_txs_features_selected.loc[(df_txs_features_selected['Time step'] >= 35) & (df_txs_features_selected['class'] != 3), 'txId']\n",
    "X_testing_timesteps_class01 = df_txs_features_selected.loc[df_txs_features_selected['txId'].isin(X_data_test_class01)]\n",
    "X_test_class01 = X_testing_timesteps_class01.drop(columns=['txId', 'class', 'Time step'])\n",
    "\n",
    "y_training_timesteps = X_training_timesteps[['class']]\n",
    "y_training_timesteps = y_training_timesteps['class'].apply(lambda x: x-1 ) # change illicit (class-2) to '0' for classification\n",
    "y_train = y_training_timesteps\n",
    "\n",
    "y_testing_timesteps = X_testing_timesteps[['class']]\n",
    "y_testing_timesteps = y_testing_timesteps['class'].apply(lambda x: x-1 ) # change illicit (class-2) to '0' for classification\n",
    "y_test = y_testing_timesteps\n",
    "\n",
    "y_testing_timesteps_class01 = X_testing_timesteps_class01[['class']]\n",
    "y_testing_timesteps_class01 = y_testing_timesteps_class01['class'].apply(lambda x: x-1 ) # change illicit (class-2) to '0' for classification\n",
    "y_test_class01 = y_testing_timesteps_class01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80cdbba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    26237\n",
       "0     3462\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec2a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_SMOTE, y_train_SMOTE = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Chuẩn bị TRAIN graph (gồm cả unknown=3) & TEST graph (chỉ 0/1)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, confusion_matrix\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# Map label: 1->0, 2->1, 3->-1 (unknown)\n",
    "def map_label(x):\n",
    "    return {1:0, 2:1}.get(x, -1)\n",
    "\n",
    "# ---- Train graph: timesteps < 35, GIỮ cả class==3 (unlabeled) ----\n",
    "train_nodes_all = df_txs_features_selected[df_txs_features_selected['Time step'] < 35].copy()\n",
    "train_nodes_all['label'] = train_nodes_all['class'].apply(map_label)\n",
    "feat_cols = [c for c in df_txs_features_selected.columns if c not in ['txId','class','Time step']]\n",
    "\n",
    "X_train_all = torch.tensor(train_nodes_all[feat_cols].values, dtype=torch.float)\n",
    "y_train_all = torch.tensor(train_nodes_all['label'].values, dtype=torch.long)\n",
    "txids_train = torch.tensor(train_nodes_all['txId'].astype(int).values, dtype=torch.long)\n",
    "\n",
    "def build_edge_index(df_edges, valid_nodes_df):\n",
    "    node_ids = valid_nodes_df['txId'].astype(int).values\n",
    "    id2idx = {tid:i for i,tid in enumerate(node_ids)}\n",
    "    edges = df_edges[(df_edges['txId1'].isin(id2idx)) & (df_edges['txId2'].isin(id2idx))].copy()\n",
    "    if len(edges) > 0:\n",
    "        edge_index = torch.tensor(\n",
    "            edges[['txId1','txId2']].replace(id2idx).values.T, dtype=torch.long\n",
    "        )\n",
    "    else:\n",
    "        edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "edge_index_train = build_edge_index(df_txs_edgelist, train_nodes_all)\n",
    "\n",
    "train_data = Data(x=X_train_all, edge_index=edge_index_train, y=y_train_all)\n",
    "train_data.node_ids = txids_train\n",
    "train_mask_init = (y_train_all >= 0)  # True cho node có nhãn 0/1\n",
    "unlabeled_mask_init = (y_train_all < 0)\n",
    "# ---- Test graph: timesteps >= 35, chỉ 0/1 ----\n",
    "test_nodes = df_txs_features_selected[\n",
    "    (df_txs_features_selected['Time step'] >= 35) & (df_txs_features_selected['class'] != 3)\n",
    "].copy()\n",
    "test_nodes['label'] = test_nodes['class'].apply(lambda x: x-1)\n",
    "\n",
    "X_test = torch.tensor(test_nodes[feat_cols].values, dtype=torch.float)\n",
    "y_test = torch.tensor(test_nodes['label'].values, dtype=torch.long)\n",
    "txids_test = torch.tensor(test_nodes['txId'].astype(int).values, dtype=torch.long)\n",
    "\n",
    "edge_index_test = build_edge_index(df_txs_edgelist, test_nodes)\n",
    "test_data = Data(x=X_test, edge_index=edge_index_test, y=y_test)\n",
    "test_data.node_ids = txids_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92326c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Model GraphSAGE\n",
    "# =========================\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=128, out_dim=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hid_dim)\n",
    "        self.conv2 = SAGEConv(hid_dim, hid_dim)\n",
    "        self.head  = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index); h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h = self.conv2(h, edge_index); h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return self.head(h)\n",
    "\n",
    "def class_weights_from_mask(y, mask):\n",
    "    y_lab = y[mask].cpu().numpy()\n",
    "    c0 = (y_lab==0).sum(); c1 = (y_lab==1).sum()\n",
    "    w = torch.tensor([1.0/(c0+1e-8), 1.0/(c1+1e-8)], dtype=torch.float)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145fe1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_df(model, data, device, name=\"TEST\"):\n",
    "    model.eval()\n",
    "    logits = model(data.x.to(device), data.edge_index.to(device))\n",
    "    preds = logits.argmax(dim=1).cpu().numpy()\n",
    "    y_true = data.y.cpu().numpy()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, preds, zero_division=0, labels=[0,1])\n",
    "    micro = f1_score(y_true, preds, average='micro', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, preds, labels=[0,1])\n",
    "    print(f\"\\n[{name}] Class0: P={prec[0]:.3f} R={rec[0]:.3f} F1={f1[0]:.3f} | \"\n",
    "          f\"Class1: P={prec[1]:.3f} R={rec[1]:.3f} F1={f1[1]:.3f} | Micro={micro:.3f}\")\n",
    "    print(\"CM:\\n\", cm)\n",
    "    # Trả DF để tiện ensemble nếu cần\n",
    "    return pd.DataFrame({\"txId\": data.node_ids.cpu().numpy(),\n",
    "                         f\"pred_{name.lower()}\": preds})\n",
    "\n",
    "def train_epochs(model, data, mask_bool, epochs=50, lr=3e-3, wd=5e-5, dropout=0.5):\n",
    "    import torch.nn.functional as F\n",
    "    model.train()\n",
    "    model.dropout = dropout\n",
    "\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    sched= torch.optim.lr_scheduler.StepLR(opt, step_size=50, gamma=0.5)\n",
    "\n",
    "    # Tính class weight từ LABELED NODES (mask_bool) — ở CPU là được\n",
    "    w = class_weights_from_mask(data.y, mask_bool).to(device)\n",
    "    crit = nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "    # Lấy chỉ số của node có nhãn rồi CHUYỂN LÊN GPU\n",
    "    idx = mask_bool.nonzero(as_tuple=False).view(-1).to(device)  # long on device\n",
    "\n",
    "    # (tuỳ chọn) kiểm tra kiểu dữ liệu\n",
    "    # assert idx.dtype == torch.long\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Đưa dữ liệu lên cùng device\n",
    "        x  = data.x.to(device)\n",
    "        ei = data.edge_index.to(device)\n",
    "        y  = data.y.to(device)        # <<< QUAN TRỌNG: y lên GPU\n",
    "\n",
    "        out = model(x, ei)            # out ở GPU\n",
    "\n",
    "        # Index-select trên CÙNG DEVICE\n",
    "        out_l = out.index_select(0, idx)\n",
    "        y_l   = y.index_select(0, idx)\n",
    "\n",
    "        loss = crit(out_l, y_l)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "\n",
    "        if ep % 10 == 0:\n",
    "            print(f\"  - ep {ep:03d} | loss={loss.item():.4f}\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def pseudo_label_once(model, data, unlabeled_mask, tau=0.95, max_add_per_class=None):\n",
    "    \"\"\"\n",
    "    Chọn pseudo-label cho node unlabeled với max prob >= tau.\n",
    "    max_add_per_class: giới hạn số lượng thêm cho mỗi lớp (int) để tránh lệch lớp; None nếu không giới hạn.\n",
    "    Trả về: idx_add (tensor cpu), y_add (tensor cpu với 0/1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    logits = model(data.x.to(device), data.edge_index.to(device))\n",
    "    prob = F.softmax(logits, dim=1).cpu()\n",
    "    unl_idx = unlabeled_mask.nonzero(as_tuple=False).view(-1)\n",
    "    if len(unl_idx) == 0:\n",
    "        return torch.empty(0, dtype=torch.long), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    prob_unl = prob.index_select(0, unl_idx)\n",
    "    conf, y_hat = prob_unl.max(dim=1)  # [num_unl], [num_unl]\n",
    "    sel = (conf >= tau)\n",
    "\n",
    "    if sel.sum().item() == 0:\n",
    "        return torch.empty(0, dtype=torch.long), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    idx_candidates = unl_idx[sel]\n",
    "    y_candidates = y_hat[sel]\n",
    "\n",
    "    # Giới hạn mỗi lớp (optional)\n",
    "    if isinstance(max_add_per_class, int):\n",
    "        idx_keep = []\n",
    "        for cls in [0,1]:\n",
    "            ids_cls = idx_candidates[(y_candidates==cls)]\n",
    "            take = ids_cls[:max_add_per_class]  # lấy đầu tiên theo thứ tự conf (đang chưa sort)\n",
    "            idx_keep.append(take)\n",
    "        idx_keep = torch.cat(idx_keep) if len(idx_keep) else torch.empty(0, dtype=torch.long)\n",
    "        mask_keep = torch.isin(idx_candidates, idx_keep)\n",
    "        idx_sel = idx_candidates[mask_keep]\n",
    "        y_sel = y_candidates[mask_keep]\n",
    "    else:\n",
    "        idx_sel = idx_candidates\n",
    "        y_sel = y_candidates\n",
    "\n",
    "    return idx_sel.cpu(), y_sel.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dac1cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Phase 0: supervised trên labeled nodes ban đầu ===\n",
      "  - ep 010 | loss=0.3350\n",
      "  - ep 020 | loss=0.2398\n",
      "  - ep 030 | loss=0.1896\n",
      "  - ep 040 | loss=0.1548\n",
      "  - ep 050 | loss=0.1323\n",
      "  - ep 060 | loss=0.1201\n",
      "  - ep 070 | loss=0.1124\n",
      "  - ep 080 | loss=0.0991\n",
      "  - ep 090 | loss=0.0929\n",
      "  - ep 100 | loss=0.0902\n",
      "  - ep 110 | loss=0.0847\n",
      "  - ep 120 | loss=0.0809\n",
      "  - ep 130 | loss=0.0795\n",
      "  - ep 140 | loss=0.0749\n",
      "  - ep 150 | loss=0.0700\n",
      "  - ep 160 | loss=0.0706\n",
      "  - ep 170 | loss=0.0689\n",
      "  - ep 180 | loss=0.0685\n",
      "  - ep 190 | loss=0.0673\n",
      "  - ep 200 | loss=0.0680\n",
      "  - ep 210 | loss=0.0637\n",
      "  - ep 220 | loss=0.0630\n",
      "  - ep 230 | loss=0.0627\n",
      "  - ep 240 | loss=0.0656\n",
      "  - ep 250 | loss=0.0652\n",
      "  - ep 260 | loss=0.0627\n",
      "  - ep 270 | loss=0.0614\n",
      "  - ep 280 | loss=0.0612\n",
      "  - ep 290 | loss=0.0617\n",
      "  - ep 300 | loss=0.0587\n",
      "\n",
      "=== Self-training round 1 (tau=0.95) ===\n",
      "  + chọn 75876 pseudo-labeled (0/1)\n",
      "  - ep 010 | loss=0.0529\n",
      "  - ep 020 | loss=0.0446\n",
      "  - ep 030 | loss=0.0357\n",
      "  - ep 040 | loss=0.0339\n",
      "  - ep 050 | loss=0.0297\n",
      "  - ep 060 | loss=0.0299\n",
      "  - ep 070 | loss=0.0292\n",
      "  - ep 080 | loss=0.0266\n",
      "\n",
      "=== Self-training round 2 (tau=0.95) ===\n",
      "  + chọn 12103 pseudo-labeled (0/1)\n",
      "  - ep 010 | loss=0.0582\n",
      "  - ep 020 | loss=0.0434\n",
      "  - ep 030 | loss=0.0354\n",
      "  - ep 040 | loss=0.0341\n",
      "  - ep 050 | loss=0.0318\n",
      "  - ep 060 | loss=0.0299\n",
      "  - ep 070 | loss=0.0294\n",
      "  - ep 080 | loss=0.0291\n",
      "\n",
      "=== Self-training round 3 (tau=0.95) ===\n",
      "  + chọn 4398 pseudo-labeled (0/1)\n",
      "  - ep 010 | loss=0.0506\n",
      "  - ep 020 | loss=0.0406\n",
      "  - ep 030 | loss=0.0346\n",
      "  - ep 040 | loss=0.0328\n",
      "  - ep 050 | loss=0.0301\n",
      "  - ep 060 | loss=0.0295\n",
      "  - ep 070 | loss=0.0290\n",
      "  - ep 080 | loss=0.0291\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2) Self-training loop\n",
    "# =========================\n",
    "in_dim = train_data.x.size(1)\n",
    "model = GraphSAGE(in_dim=in_dim, hid_dim=128, out_dim=2, dropout=0.5).to(device)\n",
    "\n",
    "# Masks khởi tạo\n",
    "labeled_mask = train_mask_init.clone()        # bool\n",
    "unlabeled_mask = unlabeled_mask_init.clone()  # bool\n",
    "y_train_work = train_data.y.clone()           # chứa -1 cho unlabeled\n",
    "\n",
    "# (Tuỳ chọn) Tách một validation window cuối (vd t=30..34) để dừng sớm -> bỏ qua cho gọn\n",
    "\n",
    "R = 3                 # số vòng self-training\n",
    "E_init = 300           # epoch train ban đầu\n",
    "E_iter = 80           # epoch train mỗi vòng\n",
    "tau = 0.95            # ngưỡng confidence\n",
    "decay = 0.0           # nếu muốn giảm ngưỡng mỗi vòng, đặt ví dụ 0.02\n",
    "\n",
    "print(\"=== Phase 0: supervised trên labeled nodes ban đầu ===\")\n",
    "train_epochs(model, train_data, labeled_mask, epochs=E_init, lr=3e-3, wd=5e-5, dropout=0.5)\n",
    "\n",
    "for r in range(1, R+1):\n",
    "    print(f\"\\n=== Self-training round {r} (tau={tau:.2f}) ===\")\n",
    "    # Chọn pseudo-label từ UNLABELED trong TRAIN graph\n",
    "    idx_add, y_add = pseudo_label_once(model, train_data, unlabeled_mask, tau=tau, max_add_per_class=None)\n",
    "    print(f\"  + chọn {len(idx_add)} pseudo-labeled (0/1)\")\n",
    "\n",
    "    if len(idx_add) == 0:\n",
    "        print(\"  + không có node đủ confidence — dừng sớm\")\n",
    "        break\n",
    "\n",
    "    # Gán nhãn & mở rộng mask\n",
    "    y_train_work[idx_add] = y_add\n",
    "    labeled_mask[idx_add] = True\n",
    "    unlabeled_mask[idx_add] = False\n",
    "    train_data.y = y_train_work  # cập nhật vào data\n",
    "\n",
    "    # Huấn luyện thêm với mask mới\n",
    "    train_epochs(model, train_data, labeled_mask, epochs=E_iter, lr=3e-3, wd=5e-5, dropout=0.5)\n",
    "\n",
    "    # (tuỳ chọn) giảm ngưỡng\n",
    "    tau = max(0.80, tau - decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "176ec070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Class0: P=0.579 R=0.684 F1=0.627 | Class1: P=0.977 R=0.965 F1=0.971 | Micro=0.946\n",
      "CM:\n",
      " [[  741   342]\n",
      " [  538 14725]]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Đánh giá\n",
    "# =========================\n",
    "_ = evaluate_df(model, test_data, device, name=\"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e72fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# GraphSAGE + Self-training (only pseudo-label class 0) on grouped graph\n",
    "# ================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, confusion_matrix\n",
    "\n",
    "# ----------------\n",
    "# 0) Config & Utils\n",
    "# ----------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_TS = list(range(1, 35))   # < 35\n",
    "TEST_TS  = list(range(35, 50))  # >= 35\n",
    "\n",
    "# Label mapping: 1->0 (licit), 2->1 (illicit), 3->-1 (unknown)\n",
    "def map_label(x):\n",
    "    return {1:0, 2:1}.get(x, -1)\n",
    "\n",
    "# Chọn cột feature\n",
    "feature_cols = [c for c in df_txs_features_selected.columns if c not in ['txId','class','Time step']]\n",
    "\n",
    "def build_edge_index(df_edges, valid_nodes_df, undirected=True):\n",
    "    \"\"\"Lọc edge theo tập node; trả về edge_index (LongTensor [2, E])\"\"\"\n",
    "    node_ids = valid_nodes_df['txId'].astype(int).values\n",
    "    id2idx = {tid:i for i, tid in enumerate(node_ids)}\n",
    "    if 'timestep' in df_edges.columns:\n",
    "        # không nối train/test; caller tự lọc theo timestep ở ngoài nếu cần\n",
    "        edges = df_edges[df_edges['txId1'].isin(id2idx) & df_edges['txId2'].isin(id2idx)].copy()\n",
    "    else:\n",
    "        edges = df_edges[df_edges['txId1'].isin(id2idx) & df_edges['txId2'].isin(id2idx)].copy()\n",
    "\n",
    "    if len(edges) > 0:\n",
    "        src = edges['txId1'].astype(int).map(id2idx).values.tolist()\n",
    "        dst = edges['txId2'].astype(int).map(id2idx).values.tolist()\n",
    "        if undirected:\n",
    "            edge_index = torch.tensor([src + dst, dst + src], dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "    return edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c760dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 1) Build TRAIN (gộp timesteps < 35, GIỮ cả class=3) & TEST (>=35, chỉ 0/1)\n",
    "# ----------------\n",
    "train_nodes_all = df_txs_features_selected[df_txs_features_selected['Time step'] < 35].copy()\n",
    "train_nodes_all['y_mapped'] = train_nodes_all['class'].apply(map_label)\n",
    "\n",
    "X_train_all = torch.tensor(train_nodes_all[feature_cols].values, dtype=torch.float)\n",
    "y_train_all = torch.tensor(train_nodes_all['y_mapped'].values, dtype=torch.long)\n",
    "train_txids = torch.tensor(train_nodes_all['txId'].astype(int).values, dtype=torch.long)\n",
    "\n",
    "edge_index_train = build_edge_index(df_txs_edgelist, train_nodes_all, undirected=True)\n",
    "\n",
    "train_data = Data(x=X_train_all, edge_index=edge_index_train, y=y_train_all)\n",
    "train_data.node_ids = train_txids\n",
    "labeled_mask   = (y_train_all >= 0)   # 0/1\n",
    "unlabeled_mask = (y_train_all <  0)   # -1\n",
    "\n",
    "# TEST: chỉ lấy class 1/2\n",
    "test_nodes = df_txs_features_selected[\n",
    "    (df_txs_features_selected['Time step'] >= 35) & (df_txs_features_selected['class'] != 3)\n",
    "].copy()\n",
    "test_nodes['y_mapped'] = test_nodes['class'].apply(lambda x: x-1)\n",
    "X_test = torch.tensor(test_nodes[feature_cols].values, dtype=torch.float)\n",
    "y_test = torch.tensor(test_nodes['y_mapped'].values, dtype=torch.long)\n",
    "test_txids = torch.tensor(test_nodes['txId'].astype(int).values, dtype=torch.long)\n",
    "edge_index_test = build_edge_index(df_txs_edgelist, test_nodes, undirected=True)\n",
    "test_data = Data(x=X_test, edge_index=edge_index_test, y=y_test)\n",
    "test_data.node_ids = test_txids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f922275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 2) Model: GraphSAGE\n",
    "# ----------------\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=128, out_dim=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hid_dim)\n",
    "        self.conv2 = SAGEConv(hid_dim, hid_dim)\n",
    "        self.head  = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index); h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h = self.conv2(h, edge_index); h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return self.head(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ddccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 3) Helper: class weights, train stage, pick unlabeled pred=0\n",
    "# ----------------\n",
    "def class_weights_from_mask(y, mask_bool):\n",
    "    y_lab = y[mask_bool].cpu().numpy()\n",
    "    c0 = (y_lab==0).sum(); c1 = (y_lab==1).sum()\n",
    "    w0 = 1.0/(c0 + 1e-8); w1 = 1.0/(c1 + 1e-8)\n",
    "    return torch.tensor([w0, w1], dtype=torch.float)\n",
    "\n",
    "def train_one_stage(model, data, labeled_mask, device, epochs=60, lr=3e-3, wd=5e-5, dropout=0.5):\n",
    "    model.train(); model.dropout = dropout\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    sched= torch.optim.lr_scheduler.StepLR(opt, step_size=50, gamma=0.5)\n",
    "    w = class_weights_from_mask(data.y, labeled_mask).to(device)\n",
    "    crit = nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        opt.zero_grad()\n",
    "        x, ei = data.x.to(device), data.edge_index.to(device)\n",
    "        y = data.y.to(device); m = labeled_mask.to(device)\n",
    "        out = model(x, ei)\n",
    "        loss = crit(out[m], y[m])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "        opt.step(); sched.step()\n",
    "        if ep % 10 == 0:\n",
    "            print(f\"  - ep {ep:03d} | loss={loss.item():.4f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def pick_unlabeled_pred0(model, data, unlabeled_mask, tau_neg=0.92, margin=0.10, device=None, max_add=None):\n",
    "    \"\"\"\n",
    "    Chỉ chọn unlabeled có dự đoán lớp 0 với p0>=tau_neg và |p1-p0|>=margin.\n",
    "    Trả về: idx_chosen (LongTensor cpu), labels (toàn 0)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x, ei = data.x.to(device), data.edge_index.to(device)\n",
    "    logits = model(x, ei)\n",
    "    prob = F.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "    p0, p1 = prob[:,0], prob[:,1]\n",
    "    pred = (p1 >= p0).astype(int)\n",
    "    margin_ok = (np.abs(p1 - p0) >= margin)\n",
    "\n",
    "    unl_idx = unlabeled_mask.nonzero(as_tuple=False).view(-1).cpu().numpy()\n",
    "    if unl_idx.size == 0:\n",
    "        return torch.empty(0, dtype=torch.long), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    cand_local = np.where((pred[unl_idx] == 0) & (p0[unl_idx] >= tau_neg) & (margin_ok[unl_idx]))[0]\n",
    "    if cand_local.size == 0:\n",
    "        return torch.empty(0, dtype=torch.long), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    # ưu tiên theo p0 giảm dần\n",
    "    order = np.argsort(-p0[unl_idx[cand_local]])\n",
    "    cand_local = cand_local[order]\n",
    "\n",
    "    if (max_add is not None) and (cand_local.size > max_add):\n",
    "        cand_local = cand_local[:max_add]\n",
    "\n",
    "    chosen_global = unl_idx[cand_local]\n",
    "    labels = np.zeros(len(chosen_global), dtype=np.int64)\n",
    "    return torch.tensor(chosen_global, dtype=torch.long), torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2652b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# 4) Self-training loop: chỉ bơm pseudo=0\n",
    "# ----------------\n",
    "def self_training_pred0_only(model, data, labeled_mask, unlabeled_mask,\n",
    "                             device,\n",
    "                             rounds=5, tau_neg=0.92, margin=0.10,\n",
    "                             decay=0.00, max_add_per_round=None,\n",
    "                             stage0_epochs=200, stageK_epochs=80):\n",
    "    print(\"=== Phase 0: supervised on labeled ===\")\n",
    "    train_one_stage(model, data, labeled_mask, device, epochs=stage0_epochs, lr=3e-3, wd=5e-5, dropout=0.5)\n",
    "\n",
    "    cur_tau = tau_neg\n",
    "    for r in range(1, rounds+1):\n",
    "        print(f\"\\n=== Round {r} (tau_neg={cur_tau:.2f}, margin={margin:.2f}) ===\")\n",
    "        idx_add, y_add = pick_unlabeled_pred0(model, data, unlabeled_mask,\n",
    "                                              tau_neg=cur_tau, margin=margin,\n",
    "                                              device=device, max_add=max_add_per_round)\n",
    "        n_add = idx_add.numel()\n",
    "        print(f\"  + will add: {n_add} pseudo negatives\")\n",
    "        if n_add == 0:\n",
    "            print(\"  + no confident negatives → stop\")\n",
    "            break\n",
    "\n",
    "        # gán nhãn & cập nhật mask\n",
    "        data.y[idx_add] = y_add.to(data.y.dtype)\n",
    "        labeled_mask[idx_add]   = True\n",
    "        unlabeled_mask[idx_add] = False\n",
    "\n",
    "        # train lại\n",
    "        train_one_stage(model, data, labeled_mask, device, epochs=stageK_epochs, lr=3e-3, wd=5e-5, dropout=0.5)\n",
    "\n",
    "        # curriculum: nới ngưỡng nếu muốn\n",
    "        cur_tau = max(0.80, cur_tau - decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fea8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Phase 0: supervised on labeled ===\n",
      "  - ep 010 | loss=0.3026\n",
      "  - ep 020 | loss=0.2166\n",
      "  - ep 030 | loss=0.1678\n",
      "  - ep 040 | loss=0.1323\n",
      "  - ep 050 | loss=0.1142\n",
      "  - ep 060 | loss=0.1026\n",
      "  - ep 070 | loss=0.0883\n",
      "  - ep 080 | loss=0.0809\n",
      "  - ep 090 | loss=0.0758\n",
      "  - ep 100 | loss=0.0699\n",
      "  - ep 110 | loss=0.0662\n",
      "  - ep 120 | loss=0.0619\n",
      "  - ep 130 | loss=0.0620\n",
      "  - ep 140 | loss=0.0563\n",
      "  - ep 150 | loss=0.0524\n",
      "  - ep 160 | loss=0.0526\n",
      "  - ep 170 | loss=0.0498\n",
      "  - ep 180 | loss=0.0525\n",
      "  - ep 190 | loss=0.0461\n",
      "  - ep 200 | loss=0.0469\n",
      "\n",
      "=== Round 1 (tau_neg=0.92, margin=0.10) ===\n",
      "  + will add: 7438 pseudo negatives\n",
      "  - ep 010 | loss=0.0609\n",
      "  - ep 020 | loss=0.0525\n",
      "  - ep 030 | loss=0.0449\n",
      "  - ep 040 | loss=0.0380\n",
      "  - ep 050 | loss=0.0370\n",
      "  - ep 060 | loss=0.0349\n",
      "  - ep 070 | loss=0.0334\n",
      "  - ep 080 | loss=0.0314\n",
      "\n",
      "=== Round 2 (tau_neg=0.92, margin=0.10) ===\n",
      "  + will add: 4449 pseudo negatives\n",
      "  - ep 010 | loss=0.0521\n",
      "  - ep 020 | loss=0.0430\n",
      "  - ep 030 | loss=0.0348\n",
      "  - ep 040 | loss=0.0364\n",
      "  - ep 050 | loss=0.0318\n",
      "  - ep 060 | loss=0.0304\n",
      "  - ep 070 | loss=0.0310\n",
      "  - ep 080 | loss=0.0292\n",
      "\n",
      "=== Round 3 (tau_neg=0.92, margin=0.10) ===\n",
      "  + will add: 4539 pseudo negatives\n",
      "  - ep 010 | loss=0.0478\n",
      "  - ep 020 | loss=0.0397\n",
      "  - ep 030 | loss=0.0344\n",
      "  - ep 040 | loss=0.0320\n",
      "  - ep 050 | loss=0.0312\n",
      "  - ep 060 | loss=0.0301\n",
      "  - ep 070 | loss=0.0288\n",
      "  - ep 080 | loss=0.0265\n",
      "\n",
      "=== Round 4 (tau_neg=0.92, margin=0.10) ===\n",
      "  + will add: 4365 pseudo negatives\n",
      "  - ep 010 | loss=0.0536\n",
      "  - ep 020 | loss=0.0399\n",
      "  - ep 030 | loss=0.0331\n",
      "  - ep 040 | loss=0.0299\n",
      "  - ep 050 | loss=0.0294\n",
      "  - ep 060 | loss=0.0279\n",
      "  - ep 070 | loss=0.0254\n",
      "  - ep 080 | loss=0.0277\n",
      "\n",
      "=== Round 5 (tau_neg=0.92, margin=0.10) ===\n",
      "  + will add: 4107 pseudo negatives\n",
      "  - ep 010 | loss=0.0515\n",
      "  - ep 020 | loss=0.0377\n",
      "  - ep 030 | loss=0.0341\n",
      "  - ep 040 | loss=0.0322\n",
      "  - ep 050 | loss=0.0295\n",
      "  - ep 060 | loss=0.0294\n",
      "  - ep 070 | loss=0.0292\n",
      "  - ep 080 | loss=0.0272\n",
      "\n",
      "[TEST] Class0: P=0.507 R=0.670 F1=0.578 | Class1: P=0.976 R=0.954 F1=0.965 | Micro=0.935\n",
      "Confusion Matrix:\n",
      " [[  726   357]\n",
      " [  705 14558]]\n"
     ]
    }
   ],
   "source": [
    "# ----------------\n",
    "# 5) Train + Self-training + Eval\n",
    "# ----------------\n",
    "model = GraphSAGE(in_dim=train_data.x.size(1), hid_dim=128, out_dim=2, dropout=0.5).to(device)\n",
    "\n",
    "# y trong data: 0/1 cho labeled, -1 cho unlabeled\n",
    "train_data.y = train_data.y.clone()  # đã là y_train_all theo map_label\n",
    "\n",
    "# chạy self-training (chỉ bơm class 0 từ unlabeled)\n",
    "self_training_pred0_only(\n",
    "    model, train_data,\n",
    "    labeled_mask=labeled_mask.clone(),\n",
    "    unlabeled_mask=unlabeled_mask.clone(),\n",
    "    device=device,\n",
    "    rounds=5,           # tăng nếu muốn\n",
    "    tau_neg=0.92,       # hạ xuống 0.90 nếu ít mẫu được thêm\n",
    "    margin=0.10,        # tăng lên 0.15 nếu muốn an toàn hơn\n",
    "    decay=0.00,         # ví dụ 0.02 để giảm dần ngưỡng mỗi vòng\n",
    "    max_add_per_round=20000,  # hoặc None\n",
    "    stage0_epochs=200,\n",
    "    stageK_epochs=80\n",
    ")\n",
    "\n",
    "# Đánh giá trên TEST\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, device, name=\"TEST\"):\n",
    "    model.eval()\n",
    "    out = model(data.x.to(device), data.edge_index.to(device))\n",
    "    preds = out.argmax(dim=1).cpu().numpy()\n",
    "    y_true = data.y.cpu().numpy()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, preds, zero_division=0, labels=[0,1])\n",
    "    micro = f1_score(y_true, preds, average='micro', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, preds, labels=[0,1])\n",
    "    print(f\"\\n[{name}] Class0: P={prec[0]:.3f} R={rec[0]:.3f} F1={f1[0]:.3f} | \"\n",
    "          f\"Class1: P={prec[1]:.3f} R={rec[1]:.3f} F1={f1[1]:.3f} | Micro={micro:.3f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "evaluate(model, test_data, device, name=\"TEST\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
