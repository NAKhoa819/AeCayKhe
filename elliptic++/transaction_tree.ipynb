{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c2f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go \n",
    "import plotly.offline as py \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a7d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3769b3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\elliptic\\elliptic++\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6087dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transaction features: \n",
      "\n",
      "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
      "0            3321          1        -0.169615        -0.184668   \n",
      "1           11108          1        -0.137586        -0.184668   \n",
      "2           51816          1        -0.170103        -0.184668   \n",
      "3           68869          1        -0.114267        -0.184668   \n",
      "4           89273          1         5.202107        -0.210553   \n",
      "...           ...        ...              ...              ...   \n",
      "203764  158304003         49        -0.165622        -0.139563   \n",
      "203765  158303998         49        -0.167040        -0.139563   \n",
      "203766  158303966         49        -0.167040        -0.139563   \n",
      "203767  161526077         49        -0.172212        -0.139573   \n",
      "203768  194103537         49        -0.172212        -0.139573   \n",
      "\n",
      "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
      "0             -1.201369        -0.121970        -0.043875        -0.113002   \n",
      "1             -1.201369        -0.121970        -0.043875        -0.113002   \n",
      "2             -1.201369        -0.121970        -0.043875        -0.113002   \n",
      "3             -1.201369         0.028105        -0.043875        -0.113002   \n",
      "4             -1.756361        -0.121970       260.090707        -0.113002   \n",
      "...                 ...              ...              ...              ...   \n",
      "203764         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203765         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203766         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203767         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "203768         1.018602        -0.121970        -0.043875        -0.113002   \n",
      "\n",
      "        Local_feature_7  Local_feature_8  ...  in_BTC_min  in_BTC_max  \\\n",
      "0             -0.061584        -0.160199  ...    0.534072    0.534072   \n",
      "1             -0.061584        -0.127429  ...    5.611878    5.611878   \n",
      "2             -0.061584        -0.160699  ...    0.456608    0.456608   \n",
      "3              0.547008        -0.161652  ...    0.308900    8.000000   \n",
      "4             -0.061584         5.335864  ...  852.164680  852.164680   \n",
      "...                 ...              ...  ...         ...         ...   \n",
      "203764        -0.061584        -0.156113  ...         NaN         NaN   \n",
      "203765        -0.061584        -0.157564  ...         NaN         NaN   \n",
      "203766        -0.061584        -0.157564  ...         NaN         NaN   \n",
      "203767        -0.061584        -0.162856  ...         NaN         NaN   \n",
      "203768        -0.061584        -0.162856  ...         NaN         NaN   \n",
      "\n",
      "        in_BTC_mean  in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  \\\n",
      "0          0.534072       0.534072      0.534072  1.668990e-01     0.367074   \n",
      "1          5.611878       5.611878      5.611878  5.861940e-01     5.025584   \n",
      "2          0.456608       0.456608      0.456608  2.279902e-01     0.228518   \n",
      "3          3.102967       1.000000      9.308900  1.229000e+00     8.079800   \n",
      "4        852.164680     852.164680    852.164680  1.300000e-07    41.264036   \n",
      "...             ...            ...           ...           ...          ...   \n",
      "203764          NaN            NaN           NaN           NaN          NaN   \n",
      "203765          NaN            NaN           NaN           NaN          NaN   \n",
      "203766          NaN            NaN           NaN           NaN          NaN   \n",
      "203767          NaN            NaN           NaN           NaN          NaN   \n",
      "203768          NaN            NaN           NaN           NaN          NaN   \n",
      "\n",
      "        out_BTC_mean  out_BTC_median  out_BTC_total  \n",
      "0           0.266986        0.266986       0.533972  \n",
      "1           2.805889        2.805889       5.611778  \n",
      "2           0.228254        0.228254       0.456508  \n",
      "3           4.654400        4.654400       9.308800  \n",
      "4           0.065016        0.000441     852.164680  \n",
      "...              ...             ...            ...  \n",
      "203764           NaN             NaN            NaN  \n",
      "203765           NaN             NaN            NaN  \n",
      "203766           NaN             NaN            NaN  \n",
      "203767           NaN             NaN            NaN  \n",
      "203768           NaN             NaN            NaN  \n",
      "\n",
      "[203769 rows x 184 columns]\n",
      "\n",
      "Transaction classes: \n",
      "\n",
      "             txId  class\n",
      "0            3321      3\n",
      "1           11108      3\n",
      "2           51816      3\n",
      "3           68869      2\n",
      "4           89273      2\n",
      "...           ...    ...\n",
      "203764  158304003      3\n",
      "203765  158303998      3\n",
      "203766  158303966      3\n",
      "203767  161526077      3\n",
      "203768  194103537      3\n",
      "\n",
      "[203769 rows x 2 columns]\n",
      "\n",
      "Transaction-Transaction edgelist: \n",
      "\n",
      "            txId1      txId2\n",
      "0       230425980    5530458\n",
      "1       232022460  232438397\n",
      "2       230460314  230459870\n",
      "3       230333930  230595899\n",
      "4       232013274  232029206\n",
      "...           ...        ...\n",
      "234350  158365409  157930723\n",
      "234351  188708874  188708879\n",
      "234352  157659064  157659046\n",
      "234353   87414554  106877725\n",
      "234354  158589452  158589457\n",
      "\n",
      "[234355 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:\\\\elliptic\\\\Elliptic_Dataset\")\n",
    "print(\"\\nTransaction features: \\n\")\n",
    "df_txs_features = pd.read_csv(\"txs_features.csv\")\n",
    "print(df_txs_features)\n",
    "\n",
    "print(\"\\nTransaction classes: \\n\")\n",
    "df_txs_classes = pd.read_csv(\"txs_classes.csv\")\n",
    "print(df_txs_classes)\n",
    "\n",
    "print(\"\\nTransaction-Transaction edgelist: \\n\")\n",
    "df_txs_edgelist = pd.read_csv(\"txs_edgelist.csv\")\n",
    "\n",
    "print(df_txs_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1defb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "txs_features.csv for txId = 272145560\n",
      "\n",
      "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
      "105573  272145560         24        -0.155493        -0.107012   \n",
      "\n",
      "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
      "105573        -1.201369         -0.12197        -0.043875        -0.113002   \n",
      "\n",
      "        Local_feature_7  Local_feature_8  ...  in_BTC_min  in_BTC_max  \\\n",
      "105573        -0.061584        -0.145749  ...      2.7732      2.7732   \n",
      "\n",
      "        in_BTC_mean  in_BTC_median  in_BTC_total  out_BTC_min  out_BTC_max  \\\n",
      "105573       2.7732         2.7732        2.7732     0.001917     2.770883   \n",
      "\n",
      "        out_BTC_mean  out_BTC_median  out_BTC_total  \n",
      "105573        1.3864          1.3864         2.7728  \n",
      "\n",
      "[1 rows x 184 columns]\n",
      "\n",
      "txs_classes.csv for txId = 272145560\n",
      "\n",
      "             txId  class\n",
      "105573  272145560      1\n",
      "\n",
      "txs_edgelist.csv for txId = 272145560\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId1</th>\n",
       "      <th>txId2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123072</th>\n",
       "      <td>272145560</td>\n",
       "      <td>296926618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123272</th>\n",
       "      <td>272145560</td>\n",
       "      <td>272145556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125873</th>\n",
       "      <td>299475624</td>\n",
       "      <td>272145560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            txId1      txId2\n",
       "123072  272145560  296926618\n",
       "123272  272145560  272145556\n",
       "125873  299475624  272145560"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\ntxs_features.csv for txId = 272145560\\n\")\n",
    "print(df_txs_features[df_txs_features['txId']==272145560])\n",
    "\n",
    "print(\"\\ntxs_classes.csv for txId = 272145560\\n\")\n",
    "print(df_txs_classes[df_txs_classes['txId']==272145560])\n",
    "\n",
    "print(\"\\ntxs_edgelist.csv for txId = 272145560\\n\")\n",
    "df_txs_edgelist[(df_txs_edgelist['txId1']==272145560) | (df_txs_edgelist['txId2']==272145560)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b034aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "3    157205\n",
      "2     42019\n",
      "1      4545\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_txs_features = df_txs_features.merge(df_txs_classes, left_on = \"txId\" , right_on = \"txId\" , how = \"left\")\n",
    "# print(txs.shape)\n",
    "\n",
    "print(df_txs_features[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2862c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>Time step</th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>1.668990e-01</td>\n",
       "      <td>0.367074</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.533972</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11108</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.127429</td>\n",
       "      <td>...</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.861940e-01</td>\n",
       "      <td>5.025584</td>\n",
       "      <td>2.805889</td>\n",
       "      <td>2.805889</td>\n",
       "      <td>5.611778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51816</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.170103</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>2.279902e-01</td>\n",
       "      <td>0.228518</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0.456508</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68869</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.114267</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>0.547008</td>\n",
       "      <td>-0.161652</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.102967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.308900</td>\n",
       "      <td>1.229000e+00</td>\n",
       "      <td>8.079800</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>9.308800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89273</td>\n",
       "      <td>1</td>\n",
       "      <td>5.202107</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>260.090707</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>5.335864</td>\n",
       "      <td>...</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>1.300000e-07</td>\n",
       "      <td>41.264036</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202799</th>\n",
       "      <td>194747812</td>\n",
       "      <td>49</td>\n",
       "      <td>0.558398</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>...</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>1.653300e+00</td>\n",
       "      <td>114.299544</td>\n",
       "      <td>57.976422</td>\n",
       "      <td>57.976422</td>\n",
       "      <td>115.952844</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202800</th>\n",
       "      <td>194747925</td>\n",
       "      <td>49</td>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>...</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>2.035300e-02</td>\n",
       "      <td>114.229700</td>\n",
       "      <td>57.125027</td>\n",
       "      <td>57.125027</td>\n",
       "      <td>114.250053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202801</th>\n",
       "      <td>194748063</td>\n",
       "      <td>49</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.569524</td>\n",
       "      <td>...</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>9.257490e-01</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>56.803363</td>\n",
       "      <td>56.803363</td>\n",
       "      <td>113.606726</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202802</th>\n",
       "      <td>194748070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.537760</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>...</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>3.026970e-01</td>\n",
       "      <td>112.378235</td>\n",
       "      <td>56.340466</td>\n",
       "      <td>56.340466</td>\n",
       "      <td>112.680932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202803</th>\n",
       "      <td>194835939</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.152788</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.161066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>3.995460e-01</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
       "0            3321          1        -0.169615        -0.184668   \n",
       "1           11108          1        -0.137586        -0.184668   \n",
       "2           51816          1        -0.170103        -0.184668   \n",
       "3           68869          1        -0.114267        -0.184668   \n",
       "4           89273          1         5.202107        -0.210553   \n",
       "...           ...        ...              ...              ...   \n",
       "202799  194747812         49         0.558398        -0.198956   \n",
       "202800  194747925         49         0.547658        -0.198956   \n",
       "202801  194748063         49         0.543600        -0.198853   \n",
       "202802  194748070         49         0.537760        -0.198853   \n",
       "202803  194835939         49        -0.170463        -0.152788   \n",
       "\n",
       "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
       "0             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "1             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "2             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "3             -1.201369         0.028105        -0.043875        -0.113002   \n",
       "4             -1.756361        -0.121970       260.090707        -0.113002   \n",
       "...                 ...              ...              ...              ...   \n",
       "202799        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202800        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202801        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202802        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202803         1.018602        -0.121970        -0.063725        -0.113002   \n",
       "\n",
       "        Local_feature_7  Local_feature_8  ...  in_BTC_max  in_BTC_mean  \\\n",
       "0             -0.061584        -0.160199  ...    0.534072     0.534072   \n",
       "1             -0.061584        -0.127429  ...    5.611878     5.611878   \n",
       "2             -0.061584        -0.160699  ...    0.456608     0.456608   \n",
       "3              0.547008        -0.161652  ...    8.000000     3.102967   \n",
       "4             -0.061584         5.335864  ...  852.164680   852.164680   \n",
       "...                 ...              ...  ...         ...          ...   \n",
       "202799        -0.061584         0.584665  ...  115.952889   115.952889   \n",
       "202800        -0.061584         0.573676  ...  114.250098   114.250098   \n",
       "202801        -0.061584         0.569524  ...  113.606771   113.606771   \n",
       "202802        -0.061584         0.563549  ...  112.680977   112.680977   \n",
       "202803        -0.061584        -0.161066  ...    0.399769     0.399769   \n",
       "\n",
       "        in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  out_BTC_mean  \\\n",
       "0            0.534072      0.534072  1.668990e-01     0.367074      0.266986   \n",
       "1            5.611878      5.611878  5.861940e-01     5.025584      2.805889   \n",
       "2            0.456608      0.456608  2.279902e-01     0.228518      0.228254   \n",
       "3            1.000000      9.308900  1.229000e+00     8.079800      4.654400   \n",
       "4          852.164680    852.164680  1.300000e-07    41.264036      0.065016   \n",
       "...               ...           ...           ...          ...           ...   \n",
       "202799     115.952889    115.952889  1.653300e+00   114.299544     57.976422   \n",
       "202800     114.250098    114.250098  2.035300e-02   114.229700     57.125027   \n",
       "202801     113.606771    113.606771  9.257490e-01   112.680977     56.803363   \n",
       "202802     112.680977    112.680977  3.026970e-01   112.378235     56.340466   \n",
       "202803       0.399769      0.399769  3.995460e-01     0.399546      0.399546   \n",
       "\n",
       "        out_BTC_median  out_BTC_total  class  \n",
       "0             0.266986       0.533972      3  \n",
       "1             2.805889       5.611778      3  \n",
       "2             0.228254       0.456508      3  \n",
       "3             4.654400       9.308800      2  \n",
       "4             0.000441     852.164680      2  \n",
       "...                ...            ...    ...  \n",
       "202799       57.976422     115.952844      3  \n",
       "202800       57.125027     114.250053      3  \n",
       "202801       56.803363     113.606726      3  \n",
       "202802       56.340466     112.680932      3  \n",
       "202803        0.399546       0.399546      3  \n",
       "\n",
       "[202804 rows x 185 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txs_features = df_txs_features.dropna()\n",
    "df_txs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a697b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_txs_features.columns[168:]:\n",
    "    if column != \"class\":\n",
    "        feature = np.array(df_txs_features[column]).reshape(-1,1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(feature)\n",
    "        feature_scaled = scaler.transform(feature)\n",
    "        df_txs_features[column] = feature_scaled.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a256a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "3    156759\n",
      "2     41500\n",
      "1      4545\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove 'unknown' transactions\n",
    "data = df_txs_features[\"txId\"] #.loc[(df_txs_features['class'] != 3), 'txId']\n",
    "df_txs_features_selected = df_txs_features.loc[df_txs_features['txId'].isin(data)]\n",
    "print(df_txs_features_selected[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10eb7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: binary classification of 0,1\n",
    "# 0: licit, 1: illicit\n",
    "\n",
    "X_data = df_txs_features_selected.loc[(df_txs_features_selected['Time step'] < 35) & (df_txs_features_selected['class'] != 3), 'txId']\n",
    "X_training_timesteps = df_txs_features_selected.loc[df_txs_features_selected['txId'].isin(X_data)]\n",
    "X_train = X_training_timesteps.drop(columns=['txId', 'class', 'Time step'])\n",
    "\n",
    "X_data_test = df_txs_features_selected.loc[(df_txs_features_selected['Time step'] >= 35), 'txId']\n",
    "X_testing_timesteps = df_txs_features_selected.loc[df_txs_features_selected['txId'].isin(X_data_test)]\n",
    "X_test = X_testing_timesteps.drop(columns=['txId', 'class', 'Time step'])\n",
    "\n",
    "X_data_test_class01 = df_txs_features_selected.loc[(df_txs_features_selected['Time step'] >= 35) & (df_txs_features_selected['class'] != 3), 'txId']\n",
    "X_testing_timesteps_class01 = df_txs_features_selected.loc[df_txs_features_selected['txId'].isin(X_data_test_class01)]\n",
    "X_test_class01 = X_testing_timesteps_class01.drop(columns=['txId', 'class', 'Time step'])\n",
    "\n",
    "y_training_timesteps = X_training_timesteps[['class']]\n",
    "y_training_timesteps = y_training_timesteps['class'].apply(lambda x: x-1 ) # change illicit (class-2) to '0' for classification\n",
    "y_train = y_training_timesteps\n",
    "\n",
    "y_testing_timesteps = X_testing_timesteps[['class']]\n",
    "y_testing_timesteps = y_testing_timesteps['class'].apply(lambda x: x-1 ) # change illicit (class-2) to '0' for classification\n",
    "y_test = y_testing_timesteps\n",
    "\n",
    "y_testing_timesteps_class01 = X_testing_timesteps_class01[['class']]\n",
    "y_testing_timesteps_class01 = y_testing_timesteps_class01['class'].apply(lambda x: x-1 ) # change illicit (class-2) to '0' for classification\n",
    "y_test_class01 = y_testing_timesteps_class01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e687f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    26237\n",
       "0     3462\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd59f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_SMOTE, y_train_SMOTE = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d5e9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    26237\n",
       "0    26237\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_SMOTE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775bc93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16346,)\n",
      "RANDOM FOREST (RF)\n",
      "\n",
      "Detailed per-class evaluation:\n",
      "Class 0:\n",
      "  Precision: 0.981\n",
      "  Recall:    0.715\n",
      "  F1 Score:  0.827\n",
      "  Support:   1083\n",
      "\n",
      "Class 1:\n",
      "  Precision: 0.980\n",
      "  Recall:    0.999\n",
      "  F1 Score:  0.989\n",
      "  Support:   15263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  774   309]\n",
      " [   15 15248]]\n",
      "\n",
      "Overall Evaluation:\n",
      "\n",
      "Micro-Average F1 Score: 0.980\n",
      "\n",
      "Macro-Average F1 Score: 0.908\n",
      "Weighted-Average F1 Score: 0.979\n",
      "Overall Accuracy: 0.980\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      "Class 0:\n",
      "  True Positives: 774 (71.5% of class 0 samples)\n",
      "  False Positives: 15\n",
      "  False Negatives: 309\n",
      "\n",
      "Class 1:\n",
      "  True Positives: 15248 (99.9% of class 1 samples)\n",
      "  False Positives: 309\n",
      "  False Negatives: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST (RF)\n",
    "cRF = RandomForestClassifier(criterion='entropy', n_estimators=50, max_depth=32 ,class_weight='balanced').fit(X_train.values,y_train.values)\n",
    "y_preds_RF_class01 = cRF.predict(X_test_class01.values)\n",
    "print(y_test_class01.shape)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_RF_class01)\n",
    "\n",
    "\n",
    "print(\"RANDOM FOREST (RF)\\n\")\n",
    "\n",
    "\n",
    "# Đánh giá từng class\n",
    "print(\"Detailed per-class evaluation:\")\n",
    "for i, label in enumerate([0, 1]):\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision: {prec[i]:.3f}\")\n",
    "    print(f\"  Recall:    {rec[i]:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1[i]:.3f}\")\n",
    "    print(f\"  Support:   {num[i]}\")\n",
    "    print()\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_RF_class01, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Đánh giá chung\n",
    "print(\"Overall Evaluation:\\n\")\n",
    "# Micro F1\n",
    "micro_f1 = f1_score(y_test_class01.values, y_preds_RF_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\\n\" % micro_f1)\n",
    "\n",
    "# Macro-average F1\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_RF_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "\n",
    "# Weighted-average F1\n",
    "weighted_f1 = f1_score(y_test_class01.values, y_preds_RF_class01, average='weighted')\n",
    "print(f\"Weighted-Average F1 Score: {weighted_f1:.3f}\")\n",
    "\n",
    "# Accuracy from confusion matrix\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "total_samples = np.sum(cm)\n",
    "for i, label in enumerate([0, 1]):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = np.sum(cm[:, i]) - true_positives\n",
    "    false_negatives = np.sum(cm[i, :]) - true_positives\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  True Positives: {true_positives} ({(true_positives / num[i] * 100):.1f}% of class {label} samples)\")\n",
    "    print(f\"  False Positives: {false_positives}\")\n",
    "    print(f\"  False Negatives: {false_negatives}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d944eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16346,)\n",
      "RANDOM FOREST (RF) + SMOTE\n",
      "\n",
      "Detailed per-class evaluation:\n",
      "Class 0:\n",
      "  Precision: 0.925\n",
      "  Recall:    0.718\n",
      "  F1 Score:  0.809\n",
      "  Support:   1083\n",
      "\n",
      "Class 1:\n",
      "  Precision: 0.980\n",
      "  Recall:    0.996\n",
      "  F1 Score:  0.988\n",
      "  Support:   15263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  778   305]\n",
      " [   63 15200]]\n",
      "\n",
      "Overall Evaluation:\n",
      "\n",
      "Micro-Average F1 Score: 0.977\n",
      "\n",
      "Macro-Average F1 Score: 0.898\n",
      "Weighted-Average F1 Score: 0.976\n",
      "Overall Accuracy: 0.977\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      "Class 0:\n",
      "  True Positives: 778 (71.8% of class 0 samples)\n",
      "  False Positives: 63\n",
      "  False Negatives: 305\n",
      "\n",
      "Class 1:\n",
      "  True Positives: 15200 (99.6% of class 1 samples)\n",
      "  False Positives: 305\n",
      "  False Negatives: 63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST (RF) + SMOTE\n",
    "cRF = RandomForestClassifier(criterion='gini', n_estimators=50, max_depth=32 ,class_weight='balanced').fit(X_train_SMOTE.values,y_train_SMOTE.values)\n",
    "y_preds_RF_class01 = cRF.predict(X_test_class01.values)\n",
    "print(y_test_class01.shape)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_RF_class01)\n",
    "\n",
    "\n",
    "print(\"RANDOM FOREST (RF) + SMOTE\\n\")\n",
    "\n",
    "\n",
    "# Đánh giá từng class\n",
    "print(\"Detailed per-class evaluation:\")\n",
    "for i, label in enumerate([0, 1]):\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision: {prec[i]:.3f}\")\n",
    "    print(f\"  Recall:    {rec[i]:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1[i]:.3f}\")\n",
    "    print(f\"  Support:   {num[i]}\")\n",
    "    print()\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_RF_class01, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Đánh giá chung\n",
    "print(\"Overall Evaluation:\\n\")\n",
    "# Micro F1\n",
    "micro_f1 = f1_score(y_test_class01.values, y_preds_RF_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\\n\" % micro_f1)\n",
    "\n",
    "# Macro-average F1\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_RF_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "\n",
    "# Weighted-average F1\n",
    "weighted_f1 = f1_score(y_test_class01.values, y_preds_RF_class01, average='weighted')\n",
    "print(f\"Weighted-Average F1 Score: {weighted_f1:.3f}\")\n",
    "\n",
    "# Accuracy from confusion matrix\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "total_samples = np.sum(cm)\n",
    "for i, label in enumerate([0, 1]):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = np.sum(cm[:, i]) - true_positives\n",
    "    false_negatives = np.sum(cm[i, :]) - true_positives\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  True Positives: {true_positives} ({(true_positives / num[i] * 100):.1f}% of class {label} samples)\")\n",
    "    print(f\"  False Positives: {false_positives}\")\n",
    "    print(f\"  False Negatives: {false_negatives}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce18fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26237, number of negative: 3462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41994\n",
      "[LightGBM] [Info] Number of data points in the train set: 29699, number of used features: 181\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "LightGBM (LGB)\n",
      "\n",
      "Detailed per-class evaluation:\n",
      "Class 0:\n",
      "  Precision: 0.893\n",
      "  Recall:    0.734\n",
      "  F1 Score:  0.806\n",
      "  Support:   1083\n",
      "\n",
      "Class 1:\n",
      "  Precision: 0.981\n",
      "  Recall:    0.994\n",
      "  F1 Score:  0.988\n",
      "  Support:   15263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  795   288]\n",
      " [   95 15168]]\n",
      "\n",
      "Overall Evaluation:\n",
      "\n",
      "Micro-Average F1 Score: 0.977\n",
      "\n",
      "Macro-Average F1 Score: 0.897\n",
      "Weighted-Average F1 Score: 0.975\n",
      "Overall Accuracy: 0.977\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      "Class 0:\n",
      "  True Positives: 795 (73.4% of class 0 samples)\n",
      "  False Positives: 95\n",
      "  False Negatives: 288\n",
      "\n",
      "Class 1:\n",
      "  True Positives: 15168 (99.4% of class 1 samples)\n",
      "  False Positives: 288\n",
      "  False Negatives: 95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "cLGB = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=32,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ").fit(X_train.values,y_train.values)\n",
    "y_preds_LGB_class01 = cLGB.predict(X_test_class01.values)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_LGB_class01)\n",
    "\n",
    "print(\"LightGBM (LGB)\\n\")\n",
    "\n",
    "\n",
    "# Đánh giá từng class\n",
    "print(\"Detailed per-class evaluation:\")\n",
    "for i, label in enumerate([0, 1]):\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision: {prec[i]:.3f}\")\n",
    "    print(f\"  Recall:    {rec[i]:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1[i]:.3f}\")\n",
    "    print(f\"  Support:   {num[i]}\")\n",
    "    print()\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_LGB_class01, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Đánh giá chung\n",
    "print(\"Overall Evaluation:\\n\")\n",
    "# Micro F1\n",
    "micro_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\\n\" % micro_f1)\n",
    "\n",
    "# Macro-average F1\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "\n",
    "# Weighted-average F1\n",
    "weighted_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='weighted')\n",
    "print(f\"Weighted-Average F1 Score: {weighted_f1:.3f}\")\n",
    "\n",
    "# Accuracy from confusion matrix\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "total_samples = np.sum(cm)\n",
    "for i, label in enumerate([0, 1]):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = np.sum(cm[:, i]) - true_positives\n",
    "    false_negatives = np.sum(cm[i, :]) - true_positives\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  True Positives: {true_positives} ({(true_positives / num[i] * 100):.1f}% of class {label} samples)\")\n",
    "    print(f\"  False Positives: {false_positives}\")\n",
    "    print(f\"  False Negatives: {false_negatives}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02c0ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26237, number of negative: 26237\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45407\n",
      "[LightGBM] [Info] Number of data points in the train set: 52474, number of used features: 181\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM (LGB)\n",
      "\n",
      "Detailed per-class evaluation:\n",
      "Class 0:\n",
      "  Precision: 0.929\n",
      "  Recall:    0.733\n",
      "  F1 Score:  0.819\n",
      "  Support:   1083\n",
      "\n",
      "Class 1:\n",
      "  Precision: 0.981\n",
      "  Recall:    0.996\n",
      "  F1 Score:  0.989\n",
      "  Support:   15263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  794   289]\n",
      " [   61 15202]]\n",
      "\n",
      "Overall Evaluation:\n",
      "\n",
      "Micro-Average F1 Score: 0.979\n",
      "\n",
      "Macro-Average F1 Score: 0.904\n",
      "Weighted-Average F1 Score: 0.977\n",
      "Overall Accuracy: 0.979\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      "Class 0:\n",
      "  True Positives: 794 (73.3% of class 0 samples)\n",
      "  False Positives: 61\n",
      "  False Negatives: 289\n",
      "\n",
      "Class 1:\n",
      "  True Positives: 15202 (99.6% of class 1 samples)\n",
      "  False Positives: 289\n",
      "  False Negatives: 61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LGBM + SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "cLGB = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=32,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ").fit(X_train_SMOTE.values,y_train_SMOTE.values)\n",
    "y_preds_LGB_class01 = cLGB.predict(X_test_class01.values)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_LGB_class01)\n",
    "\n",
    "print(\"LightGBM (LGB)\\n\")\n",
    "\n",
    "\n",
    "# Đánh giá từng class\n",
    "print(\"Detailed per-class evaluation:\")\n",
    "for i, label in enumerate([0, 1]):\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision: {prec[i]:.3f}\")\n",
    "    print(f\"  Recall:    {rec[i]:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1[i]:.3f}\")\n",
    "    print(f\"  Support:   {num[i]}\")\n",
    "    print()\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_LGB_class01, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Đánh giá chung\n",
    "print(\"Overall Evaluation:\\n\")\n",
    "# Micro F1\n",
    "micro_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\\n\" % micro_f1)\n",
    "\n",
    "# Macro-average F1\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "\n",
    "# Weighted-average F1\n",
    "weighted_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='weighted')\n",
    "print(f\"Weighted-Average F1 Score: {weighted_f1:.3f}\")\n",
    "\n",
    "# Accuracy from confusion matrix\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "total_samples = np.sum(cm)\n",
    "for i, label in enumerate([0, 1]):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = np.sum(cm[:, i]) - true_positives\n",
    "    false_negatives = np.sum(cm[i, :]) - true_positives\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  True Positives: {true_positives} ({(true_positives / num[i] * 100):.1f}% of class {label} samples)\")\n",
    "    print(f\"  False Positives: {false_positives}\")\n",
    "    print(f\"  False Negatives: {false_negatives}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d97bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST + SMOTE\n",
      "Precision: 0.921 \n",
      "Recall: 0.726 \n",
      "F1 Score: 0.812\n",
      "Micro-Average F1 Score: 0.978\n",
      "Macro-Average F1 Score: 0.904\n",
      "[[  786   297]\n",
      " [   67 15196]]\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST (XGB)\n",
    "cXGB = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=2, random_state=42, max_depth=32)\n",
    "cXGB.fit(X_train.values, y_train.values)\n",
    "y_preds_XGB_class01 = cXGB.predict(X_test_class01.values)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_XGB_class01)\n",
    "\n",
    "print(\"XGBOOST + SMOTE\")\n",
    "print(\"Precision: %.3f \\nRecall: %.3f \\nF1 Score: %.3f\"%(prec[0],rec[0],f1[0]))\n",
    "micro_f1 = f1_score(y_test_class01, y_preds_XGB_class01, average='micro')\n",
    "\n",
    "print(\"Micro-Average F1 Score: %.3f\"%(micro_f1))\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_LGB_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "#print(confusion_matrix(y, y_pred))\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_XGB_class01, labels=[0, 1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a797dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST + SMOTE\n",
      "Precision: 0.908 \n",
      "Recall: 0.728 \n",
      "F1 Score: 0.808\n",
      "Micro-Average F1 Score: 0.977\n",
      "[[  788   295]\n",
      " [   80 15183]]\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST (XGB) + SMOTE\n",
    "cXGB = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=2, random_state=42, max_depth=32)\n",
    "cXGB.fit(X_train_SMOTE.values, y_train_SMOTE.values)\n",
    "y_preds_XGB_class01 = cXGB.predict(X_test_class01.values)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_XGB_class01)\n",
    "\n",
    "print(\"XGBOOST + SMOTE\")\n",
    "print(\"Precision: %.3f \\nRecall: %.3f \\nF1 Score: %.3f\"%(prec[0],rec[0],f1[0]))\n",
    "micro_f1 = f1_score(y_test_class01, y_preds_XGB_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\"%(micro_f1))\n",
    "#print(confusion_matrix(y, y_pred))\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_XGB_class01, labels=[0, 1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26237, number of negative: 3462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41994\n",
      "[LightGBM] [Info] Number of data points in the train set: 29699, number of used features: 181\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Ensemble: LightGBM (LGB) + Random Forest (RF)\n",
      "\n",
      "Class 0:\n",
      "  Precision: 0.930\n",
      "  Recall:    0.727\n",
      "  F1 Score:  0.816\n",
      "  Support:   1083\n",
      "\n",
      "Class 1:\n",
      "  Precision: 0.981\n",
      "  Recall:    0.996\n",
      "  F1 Score:  0.988\n",
      "  Support:   15263\n",
      "\n",
      "Micro-Average F1 Score: 0.978\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  787   296]\n",
      " [   59 15204]]\n",
      "\n",
      "Overall Evaluation:\n",
      "\n",
      "Macro-Average F1 Score: 0.902\n",
      "Weighted-Average F1 Score: 0.977\n",
      "Overall Accuracy: 0.978\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      "Class 0:\n",
      "  True Positives: 787 (72.7% of class 0 samples)\n",
      "  False Positives: 59\n",
      "  False Negatives: 296\n",
      "\n",
      "Class 1:\n",
      "  True Positives: 15204 (99.6% of class 1 samples)\n",
      "  False Positives: 296\n",
      "  False Negatives: 59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of our models\n",
    "estimatorsLGBRF=[('RF', cRF), ('LGB', cLGB)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensembleLGBRF = VotingClassifier(estimatorsLGBRF, voting='soft')\n",
    "ensembleLGBRF.fit(X_train.values, y_train.values)\n",
    "y_preds_LGBRF_class01 = ensembleLGBRF.predict(X_test_class01.values)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_LGBRF_class01)\n",
    "\n",
    "print(\"Ensemble: LightGBM (LGB) + Random Forest (RF)\\n\")\n",
    "\n",
    "# In kết quả chi tiết cho từng lớp\n",
    "for i, label in enumerate([0, 1]):\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision: {prec[i]:.3f}\")\n",
    "    print(f\"  Recall:    {rec[i]:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1[i]:.3f}\")\n",
    "    print(f\"  Support:   {num[i]}\")\n",
    "    print()\n",
    "\n",
    "# Micro F1\n",
    "micro_f1 = f1_score(y_test_class01.values, y_preds_LGBRF_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\\n\" % micro_f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_LGBRF_class01, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Overall Evaluation\n",
    "print(\"Overall Evaluation:\\n\")\n",
    "# Macro-average F1\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_LGBRF_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "\n",
    "# Weighted-average F1\n",
    "weighted_f1 = f1_score(y_test_class01.values, y_preds_LGBRF_class01, average='weighted')\n",
    "print(f\"Weighted-Average F1 Score: {weighted_f1:.3f}\")\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Confusion Matrix Analysis\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "for i, label in enumerate([0, 1]):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = np.sum(cm[:, i]) - true_positives\n",
    "    false_negatives = np.sum(cm[i, :]) - true_positives\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  True Positives: {true_positives} ({(true_positives / num[i] * 100):.1f}% of class {label} samples)\")\n",
    "    print(f\"  False Positives: {false_positives}\")\n",
    "    print(f\"  False Negatives: {false_negatives}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f966c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26237, number of negative: 26237\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45407\n",
      "[LightGBM] [Info] Number of data points in the train set: 52474, number of used features: 181\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Ensemble: LightGBM (LGB) + Random Forest (RF) + SMOTE\n",
      "\n",
      "Class 0:\n",
      "  Precision: 0.946\n",
      "  Recall:    0.730\n",
      "  F1 Score:  0.824\n",
      "  Support:   1083\n",
      "\n",
      "Class 1:\n",
      "  Precision: 0.981\n",
      "  Recall:    0.997\n",
      "  F1 Score:  0.989\n",
      "  Support:   15263\n",
      "\n",
      "Micro-Average F1 Score: 0.979\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  791   292]\n",
      " [   45 15218]]\n",
      "\n",
      "Overall Evaluation:\n",
      "\n",
      "Macro-Average F1 Score: 0.907\n",
      "Weighted-Average F1 Score: 0.978\n",
      "Overall Accuracy: 0.979\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      "Class 0:\n",
      "  True Positives: 791 (73.0% of class 0 samples)\n",
      "  False Positives: 45\n",
      "  False Negatives: 292\n",
      "\n",
      "Class 1:\n",
      "  True Positives: 15218 (99.7% of class 1 samples)\n",
      "  False Positives: 292\n",
      "  False Negatives: 45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of our models\n",
    "estimatorsLGBRF=[('RF', cRF), ('LGB', cLGB)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensembleLGBRF = VotingClassifier(estimatorsLGBRF, voting='soft')\n",
    "ensembleLGBRF.fit(X_train_SMOTE.values, y_train_SMOTE.values)\n",
    "y_preds_LGBRF_class01 = ensembleLGBRF.predict(X_test_class01.values)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test_class01.values, y_preds_LGBRF_class01)\n",
    "\n",
    "print(\"Ensemble: LightGBM (LGB) + Random Forest (RF) + SMOTE\\n\")\n",
    "\n",
    "# In kết quả chi tiết cho từng lớp\n",
    "for i, label in enumerate([0, 1]):\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision: {prec[i]:.3f}\")\n",
    "    print(f\"  Recall:    {rec[i]:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1[i]:.3f}\")\n",
    "    print(f\"  Support:   {num[i]}\")\n",
    "    print()\n",
    "\n",
    "# Micro F1\n",
    "micro_f1 = f1_score(y_test_class01.values, y_preds_LGBRF_class01, average='micro')\n",
    "print(\"Micro-Average F1 Score: %.3f\\n\" % micro_f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_class01.values, y_preds_LGBRF_class01, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Overall Evaluation\n",
    "print(\"Overall Evaluation:\\n\")\n",
    "# Macro-average F1\n",
    "macro_f1 = f1_score(y_test_class01.values, y_preds_LGBRF_class01, average='macro')\n",
    "print(f\"Macro-Average F1 Score: {macro_f1:.3f}\")\n",
    "\n",
    "# Weighted-average F1\n",
    "weighted_f1 = f1_score(y_test_class01.values, y_preds_LGBRF_class01, average='weighted')\n",
    "print(f\"Weighted-Average F1 Score: {weighted_f1:.3f}\")\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Confusion Matrix Analysis\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "for i, label in enumerate([0, 1]):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = np.sum(cm[:, i]) - true_positives\n",
    "    false_negatives = np.sum(cm[i, :]) - true_positives\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  True Positives: {true_positives} ({(true_positives / num[i] * 100):.1f}% of class {label} samples)\")\n",
    "    print(f\"  False Positives: {false_positives}\")\n",
    "    print(f\"  False Negatives: {false_negatives}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
